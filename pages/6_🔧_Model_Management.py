import streamlit as st
import yfinance as yf
import pandas as pd
import plotly.graph_objects as go
import os
from agent_interactive import (
    train_and_save_rf,
    train_and_save_xgboost,
    train_and_save_lstm,
    train_and_save_prophet,
    list_saved_models,
    load_model,
    delete_model,
    deploy_model,
    undeploy_model,
    predict_with_saved_model,
    calculate_model_metrics,
    MODEL_DIR
)
from storage_manager import StorageManager, get_stock_data_cached, clear_all_caches

st.set_page_config(page_title="Model Management", page_icon="ğŸ”§", layout="wide")

st.title("ğŸ”§ ML Model Management")
st.markdown("**TrÃ¦n, gem og administrer dine egne ML modeller med custom parametre**")

# Show deployment status
all_models = list_saved_models()
deployed_models = [m for m in all_models if m.get('deployed', False)]
if deployed_models:
    st.success(f"ğŸš€ **{len(deployed_models)} deployed model(ler)** er aktive i ML Forecast og Agent Recommendations")
    with st.expander("ğŸ“‹ Se deployed modeller"):
        for m in deployed_models:
            st.markdown(f"- **{m['model_type'].upper()}** ({m['symbol']}) - {m['timestamp'][:8]}")
else:
    st.info("ğŸ’¡ Ingen deployed modeller. TrÃ¦n og deploy modeller for at bruge dem i forecasts og agent.")

st.divider()

# ==================== STORAGE & CACHE SETTINGS ====================
with st.expander("âš™ï¸ Storage & Cache Settings"):
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ’¾ Model Storage")
        storage_type = st.selectbox(
            "Storage Backend",
            ["local", "github"],
            help="Local: Ephemeral (modeller forsvinder ved redeploy)\nGitHub: Persistent via private Gists"
        )
        
        if storage_type == "github":
            if "GITHUB_TOKEN" in st.secrets:
                st.success("âœ… GitHub token configured")
            else:
                st.warning("âš ï¸ Add GITHUB_TOKEN to secrets for persistent storage")
                st.markdown("""
                **Setup:**
                1. Create GitHub Personal Access Token with `gist` scope
                2. Add to Streamlit secrets: `GITHUB_TOKEN = "your_token"`
                """)
        else:
            st.info("ğŸ“ Using local storage (ephemeral)")
    
    with col2:
        st.markdown("### ğŸš€ Cache Status")
        st.markdown("Caching reduces API calls to Yahoo Finance and NewsAPI")
        
        if st.button("ğŸ—‘ï¸ Clear All Caches", help="Clear cached stock data and news"):
            clear_all_caches()
        
        st.markdown("""
        **Cache TTL:**
        - Stock data: 1 hour
        - Stock info: 30 minutes
        - News: 1 hour
        """)
    
    with col3:
        st.markdown("### ğŸ“Š Storage Info")
        model_count = len(all_models)
        st.metric("Saved Models", model_count)
        st.metric("Deployed Models", len(deployed_models))
        
        if storage_type == "local":
            st.caption("âš ï¸ Models will be lost on redeploy")
        else:
            st.caption("âœ… Models persist across deploys")

# Initialize storage manager
storage_manager = StorageManager(storage_type=storage_type)

st.divider()

# Tabs for different functions
tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ‹ï¸ TrÃ¦n Nye Modeller", "ğŸ“‚ Gemte Modeller", "ğŸ”® Brug Gemt Model", "ğŸ§  ML Mentor", "ğŸ›ï¸ Grid Search"])

# ==================== TAB 1: TRAIN NEW MODELS ====================
with tab1:
    st.subheader("ğŸ‹ï¸ TrÃ¦n en ny model")
    st.markdown("VÃ¦lg parametre og trÃ¦n en model som du kan gemme og genbruge")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        # Data selection
        st.markdown("### ğŸ“Š Data")
        train_symbol = st.text_input("Aktie Symbol", value="AAPL", key="train_symbol")
        train_period = st.selectbox("Data Periode", ["6mo", "1y", "2y", "5y"], index=1, key="train_period")
        
        # Model type
        st.markdown("### ğŸ¤– Model Type")
        model_type = st.radio("VÃ¦lg model", ["Random Forest", "XGBoost", "LSTM", "Prophet"], key="model_type")
        
        # Common parameters
        st.markdown("### âš™ï¸ Parametre")
        if model_type != "Prophet":  # Prophet doesn't use window
            window = st.slider("Window Size", min_value=10, max_value=100, value=30, 
                              help="Antal dage brugt til features", key="window")
        else:
            window = 30  # Default for Prophet
        
        horizon = st.selectbox("Forecast Horizon", [1, 5, 22], index=0, 
                              help="Antal dage frem at forudsige", key="horizon")
        
        # Model-specific parameters
        if model_type == "Random Forest":
            st.markdown("### ğŸŒ³ Random Forest Parametre")
            n_estimators = st.slider("Antal TrÃ¦er (n_estimators)", 
                                     min_value=10, max_value=500, value=100, step=10,
                                     help="Flere trÃ¦er = bedre men langsommere")
            max_depth = st.slider("Max Dybde (max_depth)", 
                                 min_value=3, max_value=30, value=10,
                                 help="Dybde af hvert trÃ¦")
        
        elif model_type == "XGBoost":
            st.markdown("### âš¡ XGBoost Parametre")
            n_estimators = st.slider("Antal Boosts (n_estimators)", 
                                     min_value=10, max_value=500, value=100, step=10)
            max_depth = st.slider("Max Dybde (max_depth)", 
                                 min_value=3, max_value=15, value=6)
            learning_rate = st.slider("Learning Rate", 
                                     min_value=0.01, max_value=0.3, value=0.1, step=0.01,
                                     help="Lavere = mere prÃ¦cis men langsommere")
        
        elif model_type == "LSTM":
            st.markdown("### ğŸ§  LSTM Parametre")
            epochs = st.slider("Epochs", 
                              min_value=10, max_value=200, value=50, step=10,
                              help="Antal trÃ¦ningsrunder")
            st.info("LSTM bruger 2 lag med 50 enheder hver")
        
        elif model_type == "Prophet":
            st.markdown("### ğŸ“ˆ Prophet Parametre")
            daily_seasonality = st.checkbox("Daily Seasonality", value=True,
                                           help="Fang daglige mÃ¸nstre")
            weekly_seasonality = st.checkbox("Weekly Seasonality", value=True,
                                            help="Fang ugentlige mÃ¸nstre")
            st.info("Prophet er god til trends og seasonality")
        
        # Train button
        train_button = st.button("ğŸš€ TrÃ¦n Model", type="primary", use_container_width=True)
    
    with col2:
        if train_button:
            with st.spinner(f"ğŸ“¥ Henter data for {train_symbol}..."):
                try:
                    data = yf.download(train_symbol, period=train_period, progress=False)
                    
                    if isinstance(data.columns, pd.MultiIndex):
                        data.columns = data.columns.get_level_values(0)
                    
                    if data.empty:
                        st.error(f"âŒ Kunne ikke hente data for {train_symbol}")
                        st.stop()
                    
                    st.success(f"âœ… Data hentet: {len(data)} dage")
                    
                except Exception as e:
                    st.error(f"âŒ Fejl: {str(e)}")
                    st.stop()
            
            # Train model
            with st.spinner(f"ğŸ‹ï¸ TrÃ¦ner {model_type} model..."):
                try:
                    if model_type == "Random Forest":
                        result = train_and_save_rf(
                            data, train_symbol,
                            n_estimators=n_estimators,
                            max_depth=max_depth,
                            window=window,
                            horizon=horizon
                        )
                    elif model_type == "XGBoost":
                        result = train_and_save_xgboost(
                            data, train_symbol,
                            n_estimators=n_estimators,
                            max_depth=max_depth,
                            learning_rate=learning_rate,
                            window=window,
                            horizon=horizon
                        )
                    elif model_type == "LSTM":
                        from agent_interactive import train_and_save_lstm
                        result = train_and_save_lstm(
                            data, train_symbol,
                            window=window,
                            epochs=epochs,
                            horizon=horizon
                        )
                    elif model_type == "Prophet":
                        from agent_interactive import train_and_save_prophet
                        result = train_and_save_prophet(
                            data, train_symbol,
                            horizon=horizon,
                            daily_seasonality=daily_seasonality,
                            weekly_seasonality=weekly_seasonality
                        )
                    
                    if result:
                        st.success("ğŸ‰ Model trÃ¦net og gemt!")
                        
                        # Display results
                        st.markdown("### ğŸ“Š Training Resultater")
                        
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("Training MAE", f"${result['metadata']['train_mae']:.2f}")
                        with col_b:
                            st.metric("Training RMSE", f"${result['metadata']['train_rmse']:.2f}")
                        with col_c:
                            st.metric("Training Samples", result['metadata']['training_samples'])
                        
                        # Show metadata
                        with st.expander("ğŸ“‹ Model Metadata"):
                            st.json(result['metadata'])
                        
                        st.info(f"ğŸ’¾ Model gemt: `{result['filepath']}`")
                        
                except Exception as e:
                    st.error(f"âŒ Fejl ved trÃ¦ning: {str(e)}")
        else:
            # Show instructions
            st.info("""
            ### ğŸ“š SÃ¥dan trÃ¦ner du en model:
            
            1. **VÃ¦lg data**: Aktie symbol og periode
            2. **VÃ¦lg model type**: Random Forest eller XGBoost
            3. **Juster parametre**: 
               - **Window Size**: Hvor mange dage historik modellen bruger
               - **Horizon**: Hvor langt frem den forudsiger
               - **Model parametre**: Juster efter behov
            4. **Klik "TrÃ¦n Model"**: Modellen trÃ¦nes og gemmes automatisk
            
            ### ğŸ’¡ Tips til parametre:
            
            **Random Forest:**
            - Flere trÃ¦er = bedre performance men langsommere
            - HÃ¸jere max_depth = mere kompleks model
            - Start med 100 trÃ¦er, depth 10
            
            **XGBoost:**
            - Typisk hurtigere end Random Forest
            - Learning rate: 0.1 er et godt udgangspunkt
            - Lavere learning rate = mere prÃ¦cis men krÃ¦ver flere estimators
            
            **Window & Horizon:**
            - Window: 30 dage er standard
            - Horizon: 1 dag for daglig trading, 5-22 for lÃ¦ngere
            """)

# ==================== TAB 2: SAVED MODELS ====================
with tab2:
    st.subheader("ğŸ“‚ Gemte Modeller")
    
    # ========== BULK CLEANUP SECTION ==========
    with st.expander("ğŸ—‘ï¸ **Bulk Cleanup** - Slet flere modeller pÃ¥ Ã©n gang"):
        st.markdown("**âš ï¸ ADVARSEL:** Denne funktion sletter modeller permanent!")
        
        cleanup_col1, cleanup_col2 = st.columns([2, 1])
        
        with cleanup_col1:
            # Get all models with metrics
            import json
            from collections import defaultdict
            
            all_models_cleanup = list_saved_models()
            models_with_metrics = []
            
            for model_info in all_models_cleanup:
                log_file = model_info['filepath'].replace('.pkl', '_training.json').replace('.h5', '_training.json')
                if os.path.exists(log_file):
                    with open(log_file, 'r') as f:
                        log_data = json.load(f)
                        model_info['val_mae'] = log_data.get('metrics', {}).get('val_mae', 0)
                        model_info['version'] = log_data.get('version', 1)
                        model_info['description'] = log_data.get('description', '')
                else:
                    model_info['val_mae'] = 0
                    model_info['version'] = 1
                    model_info['description'] = ''
                models_with_metrics.append(model_info)
            
            # Cleanup filters
            st.markdown("**ğŸ“‹ VÃ¦lg hvilke modeller der skal slettes:**")
            
            cleanup_criteria = st.radio(
                "Cleanup kriterie",
                ["ğŸ¯ Manuel valg", "ğŸ“Š Performance filter", "ğŸ”¢ Version filter"],
                horizontal=True
            )
            
            models_to_delete = []
            
            if cleanup_criteria == "ğŸ¯ Manuel valg":
                st.markdown("**VÃ¦lg modeller til sletning:**")
                
                # Group by symbol for better organization
                grouped_cleanup = defaultdict(list)
                for m in models_with_metrics:
                    grouped_cleanup[m['symbol']].append(m)
                
                for symbol in sorted(grouped_cleanup.keys()):
                    st.markdown(f"**{symbol}:**")
                    for model in grouped_cleanup[symbol]:
                        label = f"{model['model_type'].upper()} v{model['version']} - Val MAE: ${model['val_mae']:.2f}"
                        if model.get('description'):
                            label += f" - {model['description'][:50]}"
                        
                        if st.checkbox(label, key=f"cleanup_check_{model['filename']}"):
                            models_to_delete.append(model)
            
            elif cleanup_criteria == "ğŸ“Š Performance filter":
                st.markdown("**Slet modeller med dÃ¥rlig performance:**")
                
                mae_threshold = st.slider(
                    "Val MAE > threshold (hÃ¸jere = vÃ¦rre)",
                    min_value=0.0,
                    max_value=50.0,
                    value=20.0,
                    step=1.0,
                    help="Modeller med Val MAE hÃ¸jere end denne vÃ¦rdi vil blive slettet"
                )
                
                # Find models above threshold
                for model in models_with_metrics:
                    if model['val_mae'] > mae_threshold:
                        models_to_delete.append(model)
                
                if models_to_delete:
                    st.warning(f"âš ï¸ **{len(models_to_delete)} modeller** har Val MAE > ${mae_threshold:.2f}:")
                    for m in models_to_delete[:10]:  # Show first 10
                        st.markdown(f"- {m['model_type'].upper()} {m['symbol']} v{m['version']}: ${m['val_mae']:.2f}")
                    if len(models_to_delete) > 10:
                        st.markdown(f"... og {len(models_to_delete) - 10} flere")
                else:
                    st.info("âœ… Ingen modeller over threshold")
            
            elif cleanup_criteria == "ğŸ”¢ Version filter":
                st.markdown("**Slet gamle versioner:**")
                
                keep_latest = st.number_input(
                    "Behold seneste X versioner pr. symbol+type",
                    min_value=1,
                    max_value=10,
                    value=3,
                    help="F.eks. ved at vÃ¦lge 3, beholdes kun v3, v4, v5 og Ã¦ldre versioner slettes"
                )
                
                # Group by symbol + type
                grouped_versions = defaultdict(list)
                for model in models_with_metrics:
                    key = f"{model['symbol']}_{model['model_type']}"
                    grouped_versions[key].append(model)
                
                # Find models to delete
                for key, models in grouped_versions.items():
                    # Sort by version (newest first)
                    models_sorted = sorted(models, key=lambda m: m['version'], reverse=True)
                    
                    # Mark old versions for deletion
                    if len(models_sorted) > keep_latest:
                        models_to_delete.extend(models_sorted[keep_latest:])
                
                if models_to_delete:
                    st.warning(f"âš ï¸ **{len(models_to_delete)} gamle versioner** vil blive slettet:")
                    for m in models_to_delete[:10]:  # Show first 10
                        st.markdown(f"- {m['model_type'].upper()} {m['symbol']} v{m['version']}")
                    if len(models_to_delete) > 10:
                        st.markdown(f"... og {len(models_to_delete) - 10} flere")
                else:
                    st.info("âœ… Alle modeller er inden for grÃ¦nsen")
        
        with cleanup_col2:
            st.markdown("### ğŸ“Š Cleanup Stats")
            
            if models_to_delete:
                st.error(f"**{len(models_to_delete)}** modeller")
                st.markdown("vil blive slettet")
                
                # Show breakdown by type
                type_counts = defaultdict(int)
                for m in models_to_delete:
                    type_counts[m['model_type']] += 1
                
                for mtype, count in sorted(type_counts.items()):
                    st.markdown(f"- {mtype.upper()}: {count}")
                
                st.markdown("---")
                
                # Confirmation
                confirm = st.checkbox("âœ… Ja, slet disse modeller", key="cleanup_confirm")
                
                if confirm:
                    if st.button("ğŸ—‘ï¸ **SLET NU**", type="primary", use_container_width=True):
                        deleted_count = 0
                        failed_count = 0
                        
                        with st.spinner("Sletter modeller..."):
                            for model in models_to_delete:
                                if delete_model(model['filepath']):
                                    deleted_count += 1
                                else:
                                    failed_count += 1
                        
                        if deleted_count > 0:
                            st.success(f"âœ… Slettede {deleted_count} modeller!")
                        if failed_count > 0:
                            st.error(f"âŒ Kunne ikke slette {failed_count} modeller")
                        
                        st.rerun()
                else:
                    st.info("ğŸ‘† BekrÃ¦ft fÃ¸rst")
            else:
                st.info("ğŸ“­ Ingen modeller valgt")
    
    st.divider()
    
    # View toggle
    view_col1, view_col2, view_col3 = st.columns([1, 1, 2])
    with view_col1:
        view_mode = st.radio("Visning", ["ğŸ—‚ï¸ Grupperet", "ğŸ“‹ Liste"], horizontal=True, key="view_mode")
    with view_col2:
        if view_mode == "ğŸ“‹ Liste":
            filter_type = st.selectbox("Filtrer type", ["Alle", "rf", "xgboost", "lstm"], key="filter_type")
    with view_col3:
        st.write("")  # Spacer
    
    # Get all saved models
    all_saved_models = list_saved_models()
    
    if not all_saved_models:
        st.info("ğŸ“­ Ingen gemte modeller fundet. TrÃ¦n en model i 'TrÃ¦n Nye Modeller' tab.")
    else:
        st.success(f"ğŸ“¦ Total: {len(all_saved_models)} model(ler)")
        
        # ========== GRUPPERET VISNING ==========
        if view_mode == "ğŸ—‚ï¸ Grupperet":
            # Group models by symbol and type
            from collections import defaultdict
            import json
            
            grouped = defaultdict(lambda: defaultdict(list))
            
            for model_info in all_saved_models:
                symbol = model_info['symbol']
                model_type = model_info['model_type']
                
                # Load training log to get metrics
                log_file = model_info['filepath'].replace('.pkl', '_training.json').replace('.h5', '_training.json')
                if os.path.exists(log_file):
                    with open(log_file, 'r') as f:
                        log_data = json.load(f)
                        model_info['metrics'] = log_data.get('metrics', {})
                        model_info['version'] = log_data.get('version', 1)
                        model_info['description'] = log_data.get('description', '')
                else:
                    model_info['metrics'] = {}
                    model_info['version'] = 1
                    model_info['description'] = ''
                
                grouped[symbol][model_type].append(model_info)
            
            # Display grouped models
            for symbol in sorted(grouped.keys()):
                st.markdown(f"### ğŸ“Š {symbol}")
                
                for model_type in sorted(grouped[symbol].keys()):
                    models = grouped[symbol][model_type]
                    model_count = len(models)
                    
                    # Find best model (lowest val_mae)
                    best_model = min(models, key=lambda m: m.get('metrics', {}).get('val_mae', float('inf')))
                    best_mae = best_model.get('metrics', {}).get('val_mae', 0)
                    
                    with st.expander(f"ğŸ¤– **{model_type.upper()}** ({model_count} versions) - Best: ${best_mae:.2f} â­"):
                        # Sort by version (newest first)
                        models_sorted = sorted(models, key=lambda m: m['version'], reverse=True)
                        
                        # Display each version
                        for model_info in models_sorted:
                            is_best = model_info == best_model
                            version = model_info['version']
                            description = model_info['description']
                            val_mae = model_info.get('metrics', {}).get('val_mae', 0)
                            
                            st.markdown("---")
                            
                            col_a, col_b = st.columns([3, 1])
                            
                            with col_a:
                                badge = "â­ **BEST**" if is_best else ""
                                st.markdown(f"**v{version}** {badge}")
                                if description:
                                    st.caption(description)
                                st.markdown(f"Val MAE: **${val_mae:.2f}**")
                                st.caption(f"ğŸ“… {model_info['timestamp']}")
                            
                            with col_b:
                                # Deployment
                                is_deployed = model_info.get('deployed', False)
                                if is_deployed:
                                    st.success("âœ… DEPLOYED")
                                    if st.button("â¸ï¸ Undeploy", key=f"undeploy_grp_{model_info['filename']}", use_container_width=True):
                                        from agent_interactive import undeploy_model
                                        if undeploy_model(model_info['filepath']):
                                            st.success("âœ… Undeployed!")
                                            st.rerun()
                                else:
                                    if st.button("ğŸš€ Deploy", key=f"deploy_grp_{model_info['filename']}", use_container_width=True):
                                        from agent_interactive import deploy_model
                                        if deploy_model(model_info['filepath']):
                                            st.success("âœ… Deployed!")
                                            st.rerun()
                                
                                # Delete button
                                if st.button("ğŸ—‘ï¸ Slet", key=f"delete_grp_{model_info['filename']}", use_container_width=True):
                                    if delete_model(model_info['filepath']):
                                        st.success("âœ… Slettet!")
                                        st.rerun()
                
                st.markdown("")  # Spacer between symbols
        
        # ========== LISTE VISNING ==========
        else:
            # Filter models
            model_type_filter = None if filter_type == "Alle" else filter_type
            saved_models = list_saved_models(model_type=model_type_filter)
            
            if not saved_models:
                st.info("ï¿½ Ingen modeller matcher filteret.")
            else:
                st.markdown(f"**{len(saved_models)} model(ler)** matcher filter")
                
                # Display models in cards
                for i, model_info in enumerate(saved_models):
                    with st.expander(f"ğŸ¤– {model_info['model_type'].upper()} - {model_info['symbol']} ({model_info['timestamp']})"):
                        col_a, col_b = st.columns([2, 1])
                
                with col_a:
                    st.markdown(f"**Model Type:** {model_info['model_type'].upper()}")
                    st.markdown(f"**Symbol:** {model_info['symbol']}")
                    st.markdown(f"**Timestamp:** {model_info['timestamp']}")
                    
                    if 'metadata' in model_info:
                        meta = model_info['metadata']
                        st.markdown(f"**Window:** {meta.get('window', 'N/A')}")
                        st.markdown(f"**Horizon:** {meta.get('horizon', 'N/A')}")
                        st.markdown(f"**Training MAE:** ${meta.get('train_mae', 'N/A'):.2f}")
                        st.markdown(f"**Training RMSE:** ${meta.get('train_rmse', 'N/A'):.2f}")
                        
                        with st.expander("ğŸ“‹ Fuld Metadata"):
                            st.json(meta)
                
                with col_b:
                    # Deployment status
                    is_deployed = model_info.get('deployed', False)
                    if is_deployed:
                        st.success("âœ… DEPLOYED")
                    else:
                        st.info("â¸ï¸ Not Deployed")
                    
                    # Action buttons
                    if is_deployed:
                        if st.button(f"â¸ï¸ Undeploy", key=f"undeploy_{i}", use_container_width=True):
                            from agent_interactive import undeploy_model
                            if undeploy_model(model_info['filepath']):
                                st.success("âœ… Model undeployed!")
                                st.rerun()
                    else:
                        if st.button(f"ğŸš€ Deploy", key=f"deploy_{i}", use_container_width=True):
                            from agent_interactive import deploy_model
                            if deploy_model(model_info['filepath']):
                                st.success("âœ… Model deployed!")
                                st.rerun()
                    
                    if st.button(f"ğŸ—‘ï¸ Slet", key=f"delete_{i}", use_container_width=True):
                        if delete_model(model_info['filepath']):
                            st.success("âœ… Model slettet!")
                            st.rerun()
                    
                    st.markdown(f"`{model_info['filename']}`")

# ==================== TAB 3: USE SAVED MODEL ====================
with tab3:
    st.subheader("ğŸ”® Brug en gemt model til prediction")
    
    # Get all saved models
    all_models = list_saved_models()
    
    if not all_models:
        st.info("ğŸ“­ Ingen gemte modeller. TrÃ¦n fÃ¸rst en model i 'TrÃ¦n Nye Modeller' tab.")
    else:
        # Model selection
        model_options = [f"{m['model_type'].upper()} - {m['symbol']} ({m['timestamp']})" for m in all_models]
        selected_idx = st.selectbox("VÃ¦lg model", range(len(model_options)), 
                                    format_func=lambda x: model_options[x])
        
        selected_model_info = all_models[selected_idx]
        
        # Show model info
        with st.expander("â„¹ï¸ Model Information", expanded=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Model Type", selected_model_info['model_type'].upper())
            with col2:
                st.metric("Symbol", selected_model_info['symbol'])
            with col3:
                st.metric("Training MAE", f"${selected_model_info['metadata'].get('train_mae', 0):.2f}")
        
        # Data for prediction
        st.markdown("### ğŸ“Š Prediction Data")
        use_same_symbol = st.checkbox("Brug samme symbol som trÃ¦ning", value=True)
        
        if use_same_symbol:
            pred_symbol = selected_model_info['symbol']
            st.info(f"Bruger symbol: {pred_symbol}")
        else:
            pred_symbol = st.text_input("Andet symbol", value="AAPL")
        
        pred_period = st.selectbox("Data periode", ["1mo", "3mo", "6mo", "1y"], index=2)
        
        # Predict button
        if st.button("ğŸ”® Lav Prediction", type="primary", use_container_width=True):
            with st.spinner(f"ğŸ“¥ Henter data for {pred_symbol}..."):
                try:
                    data = yf.download(pred_symbol, period=pred_period, progress=False)
                    
                    if isinstance(data.columns, pd.MultiIndex):
                        data.columns = data.columns.get_level_values(0)
                    
                    if data.empty:
                        st.error(f"âŒ Kunne ikke hente data")
                        st.stop()
                    
                except Exception as e:
                    st.error(f"âŒ Fejl: {str(e)}")
                    st.stop()
            
            # Load and use model
            with st.spinner("ğŸ”® Laver prediction..."):
                try:
                    model_package = load_model(selected_model_info['filepath'])
                    
                    if model_package:
                        result = predict_with_saved_model(
                            model_package, 
                            data, 
                            horizon=selected_model_info['metadata'].get('horizon', 1)
                        )
                        
                        if result:
                            st.success("âœ… Prediction komplet!")
                            
                            # Display results
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.metric("Current Price", f"${result['current']:.2f}")
                            with col2:
                                st.metric("Predicted Price", f"${result['forecast']:.2f}",
                                         delta=f"{result['change_pct']:.2f}%")
                            with col3:
                                direction = "ğŸ“ˆ UP" if result['change_pct'] > 0 else "ğŸ“‰ DOWN"
                                st.metric("Direction", direction)
                            
                            # Chart
                            st.markdown("### ğŸ“ˆ Price Chart")
                            fig = go.Figure()
                            
                            fig.add_trace(go.Scatter(
                                x=data.index,
                                y=data['Close'],
                                mode='lines',
                                name='Historical Price',
                                line=dict(color='lightblue', width=2)
                            ))
                            
                            # Add prediction point
                            from datetime import timedelta
                            horizon_days = selected_model_info['metadata'].get('horizon', 1)
                            pred_date = data.index[-1] + timedelta(days=horizon_days)
                            
                            fig.add_trace(go.Scatter(
                                x=[pred_date],
                                y=[result['forecast']],
                                mode='markers',
                                name='Prediction',
                                marker=dict(color='red', size=15, symbol='star')
                            ))
                            
                            fig.update_layout(
                                title=f"{pred_symbol} - Prediction med gemt model",
                                xaxis_title="Date",
                                yaxis_title="Price (USD)",
                                template="plotly_dark",
                                height=500
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                        
                except Exception as e:
                    st.error(f"âŒ Fejl ved prediction: {str(e)}")

# ==================== TAB 4: ML MENTOR (DISABLED FOR DEPLOYMENT) ====================
with tab4:
    st.subheader("ğŸ§  ML Mentor - Intelligent Model Analysis")
    st.markdown("**AI-drevet analyse af dine trÃ¦nede modeller med actionable anbefalinger**")
    
    st.warning("âš ï¸ **ML Mentor feature er midlertidigt disabled for denne deployment**")
    st.markdown("""
    ML Mentor krÃ¦ver eksterne dependencies (`ml_mentor_engine.py`, `ml_mentor_retrain.py`) 
    der ikke er inkluderet i denne deployment version.
    
    **Features (kommer i nÃ¦ste version):**
    - ğŸ¤– AI-powered model analysis med GPT-4
    - ğŸ“Š Health score calculation (0-100)
    - ğŸ’¡ Actionable recommendations
    - ğŸ”„ Auto-retrain med anbefalinger
    - ğŸ“ˆ Before/after comparison
    - ğŸ“‰ Training curve visualisering
    
    **For now:** Brug "Gemte Modeller" tab til at se model metrics og performance.
    """)
    
    # Original ML Mentor code disabled for deployment
    # Requires: ml_mentor_engine.py, ml_mentor_retrain.py
    
    # Skipping 800+ lines of ML Mentor implementation
    # All code from here to line 1524 "except ImportError" has been disabled
        
    try:
        pass
    except ImportError:
        st.error("âŒ ml_mentor_engine.py ikke fundet. SÃ¸rg for at filen er i samme directory.")

# Footer info
st.divider()
st.markdown("""
### ğŸ’¡ Om Model Management

Denne side lader dig:
- **TrÃ¦ne** modeller med custom parametre
- **Gemme** modeller til senere brug
- **Administrere** dine gemte modeller
- **Genbruge** modeller pÃ¥ ny data
- **Analysere** med ML Mentor â­ NEW!

**Fordele ved at gemme modeller:**
- â±ï¸ Spar tid - trÃ¦n Ã©n gang, brug mange gange
- ğŸ¯ Sammenlign forskellige parametersÃ¦t
- ğŸ“Š Track performance over tid
- ğŸ”„ Brug samme model pÃ¥ flere aktier
- ğŸ§  FÃ¥ AI-drevne anbefalinger

**Modellerne gemmes i:** `{MODEL_DIR}/`
""")

# ==================== TAB 5: GRID SEARCH (DISABLED FOR DEPLOYMENT) ====================
with tab5:
    st.subheader("ğŸ›ï¸ Grid Search - Automated Hyperparameter Tuning")
    st.markdown("**Automatisk find de bedste hyperparametre for dine modeller**")
    
    st.warning("âš ï¸ **Grid Search feature er midlertidigt disabled for denne deployment**")
    st.markdown("""
    Grid Search krÃ¦ver eksterne dependencies (`grid_search_engine.py`) 
    der ikke er inkluderet i denne deployment version.
    
    **Features (kommer i nÃ¦ste version):**
    - ğŸ” Automated hyperparameter search
    - ğŸ“Š Small/Medium/Large search spaces
    - âš¡ Parallel execution
    - ğŸ“ˆ Best model identification
    - ğŸ“ Search history tracking
    
    **For now:** Brug "TrÃ¦n Nye Modeller" tab til at eksperimentere med forskellige hyperparametre manuelt.
    """)
    
    # Original Grid Search code disabled
    try:
        pass
    except ImportError:
        st.error("âŒ grid_search_engine.py ikke fundet.")
    
    # Below: ~260 lines of Grid Search implementation disabled
    # (All code removed for deployment)
